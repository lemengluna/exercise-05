---
title: "exercise-05"
author: "lemeng"
format: html
---

## Challenge 1

```{r}
library(tidyverse)
library(dplyr)
```

step 1-3

```{r}
d <- read_csv("https://raw.githubusercontent.com/difiore/ada-datasets/main/IMDB-movies.csv")
d <- d %>% filter(runtimeMinutes >= 60 & runtimeMinutes <= 180) %>% filter(startYear >= 1920 & startYear <= 1979) %>% mutate(decade = case_when(
  startYear >= 1920 & startYear < 1930 ~ "20s",
  startYear >= 1930 & startYear < 1940 ~ "30s",
  startYear >= 1940 & startYear < 1950 ~ "40s",
  startYear >= 1950 & startYear < 1960 ~ "50s",
  startYear >= 1960 & startYear < 1970 ~ "60s",
  startYear >= 1970 & startYear < 1980 ~ "70s"
))

ggplot(d)+
  geom_histogram(aes(runtimeMinutes))+
  facet_wrap(vars(decade))

```

step 4-6

```{r}

results <- data.frame("population_mean" = mean(d$runtimeMinutes), "population_sd" = sd(d$runtimeMinutes))

sample_results <- d %>% 
  group_by(decade) %>% 
  slice_sample(n=100, replace = F) %>% 
  summarise(
    sample_mean = mean(runtimeMinutes, na.rm=T),
    sample_sd = sd(runtimeMinutes, na.rm = T)
  )

sample_results <- sample_results %>% 
  mutate(sample_se = sample_sd/sqrt(100))


```

step 7

```{r}
population_result <- d %>% 
  group_by(decade) %>% 
  summarise(
    population_mean = mean(runtimeMinutes, na.rm=T),
    population_sd = sd(runtimeMinutes, na.rm=T),
    population_se = sd(runtimeMinutes, na.rm=T)/sqrt(100)
  )

comparision <- left_join(sample_results, population_result, by="decade")

comparision_mean_long <- comparision %>% 
  pivot_longer(cols=c(population_mean, sample_mean),
               names_to = "type", values_to = "mean")

ggplot(comparision_mean_long, aes(x = decade, y = mean, fill = type)) + geom_bar(stat = "identity", position = "dodge")
# The sample means and population means are generally aligned with small deviations. This indicates the sample means are good approximations of the population means.

comparision_se_long <- comparision %>% 
  pivot_longer(cols=c(population_se, sample_se),
               names_to = "type", values_to = "se")
ggplot(comparision_se_long, aes(x = decade, y = se, fill = type)) + geom_bar(stat = "identity", position = "dodge")
# The sample SEs and population SEs are generally aligned with small deviations. This indicates the sample SEs are good approximations of the population SEs.

```

step 8

```{r}
library(mosaic)

sampling_distribution <- d %>% 
  group_by(decade) %>% 
  do(data.frame(
    sample_mean = replicate(1000, mean(sample(d$runtimeMinutes, 100, replace = F ), na.rm=T)),
    sample_sd = replicate(1000, sd(sample(d$runtimeMinutes, 100, replace = F ), na.rm=T))
  ))

sampling_summary <- sampling_distribution %>%
  group_by(decade) %>%
  summarise(
    mean_of_sample_means = mean(sample_mean, na.rm = TRUE),
    sd_of_sample_means = sd(sample_mean, na.rm = TRUE))

ggplot(sampling_distribution, aes(x = sample_mean)) +
  geom_histogram(binwidth = 2, fill = "blue", alpha = 0.7, color = "black") +
  facet_wrap(~decade)

ggplot(sampling_distribution, aes(x = sample_sd)) +
  geom_histogram(binwidth = 2, fill = "blue", alpha = 0.7, color = "black") +
  facet_wrap(~decade)

```

The shape is a normal distribution due to the Central Limit Theorem.

step 10

```{r}
#1
first_sample_se <- d %>% 
  group_by(decade) %>% 
  slice_sample(n=100) %>% 
  summarise(first_sample_se = sd(runtimeMinutes, na.rm=T)/sqrt(100))

#2
population_se <- population_result %>% 
  select(decade, population_se)

#3
sampling_se <- sampling_summary %>% 
  select(decade, sd_of_sample_means)

se_comparision <- left_join(
  first_sample_se,
  population_se,
  by="decade"
) %>% left_join(sampling_se, by="decade")

print(se_comparision)
```

The comparison shows that the SE estimated from the sampling distribution are generally close to the SE from the population, indicating the repeated sampling is a reliable estimate of the true SE.

However, the SE from the first sample generally shows a larger deviation from the true SE, which means statistics from the first sample is not always reliable due to sampling variability.

Although the SE from the first sample is expected to be larger than the SE from the sampling distribution, it is not true for all cases. This can be explained by the variability in random sampling.

## Challenge 2

step1-2

```{r}
z <- read_csv("https://raw.githubusercontent.com/difiore/ada-datasets/main/zombies.csv")

stats <- z %>% 
  summarise(
    mean_height = mean(height),
    sd_height = sqrt(sum((height - mean_height)^2)/n()),
    mean_weight = mean(weight),
    sd_weight = sqrt(sum((weight - mean_weight)^2)/n()),
    mean_age = mean(age),
    sd_age = sqrt(sum((age - mean_age)^2)/n()),
    mean_num = mean(zombies_killed),
    sd_num = sqrt(sum((zombies_killed - mean_num)^2)/n()),
    mean_edu = mean(years_of_education),
    sd_edu = sqrt(sum((years_of_education - mean_height)^2)/n())
  )
```

step 3

```{r}
ggplot(z)+
  geom_boxplot(aes(x=gender, y=height))

ggplot(z)+
  geom_boxplot(aes(x=gender, y=weight))

ggplot(z)+
  geom_boxplot(aes(x=gender, y=age))

ggplot(z)+
  geom_boxplot(aes(x=gender, y=zombies_killed))

ggplot(z)+
  geom_boxplot(aes(x=gender, y=years_of_education))

```

step 4

```{r}
ggplot(z)+
  geom_point(aes(x=age, y=height, color=gender))

ggplot(z)+
  geom_point(aes(x=age, y=weight, color=gender))

```

Height and weight seem to have a positive correlation with age. As age increases, height and weight tend to increase. Also, males have an overall higher height and weight values.

step 5

```{r}
hist(z$height)
qqnorm(z$height)

hist(z$weight)
qqnorm(z$weight)

hist(z$age)
qqnorm(z$age)

hist(z$zombies_killed)
qqnorm(z$zombies_killed)

hist(z$years_of_education)
qqnorm(z$years_of_education)
```

Height, weight, and age are drawn from a normal distribution. Number of years of education and number of zombies they have killed are not. They are likely drawn from a poisson distribution.

step 6

```{r}
s_z <- z %>% 
  slice_sample(n=50, replace = F) %>% 
  summarise(
    mean_height = mean(height),
    se_height = sd(height) / sqrt(50),
    ci_lower_height = mean_height - 1.96 * se_height,
    ci_upper_height = mean_height + 1.96 * se_height,

    mean_weight = mean(weight),
    se_weight = sd(weight) / sqrt(50),
    ci_lower_weight = mean_weight - 1.96 * se_weight,
    ci_upper_weight = mean_weight + 1.96 * se_weight,

    mean_age = mean(age),
    se_age = sd(age) / sqrt(50),
    ci_lower_age = mean_age - 1.96 * se_age,
    ci_upper_age = mean_age + 1.96 * se_age,

    mean_num = mean(zombies_killed),
    se_num = sd(zombies_killed) / sqrt(50),
    ci_lower_num = mean_num - 1.96 * se_num,
    ci_upper_num = mean_num + 1.96 * se_num,

    mean_edu = mean(years_of_education),
    se_edu = sd(years_of_education) / sqrt(50),
    ci_lower_edu = mean_edu - 1.96 * se_edu,
    ci_upper_edu = mean_edu + 1.96 * se_edu
  ) 
```

step 7

```{r}

s_199 <- z %>% 
    do(data.frame(
    mean_height = replicate(199, mean(sample(z$height, 50, replace = F ), na.rm=T)),
    mean_weight = replicate(199, mean(sample(z$weight, 50, replace = F ), na.rm=T)),
    mean_age = replicate(199, mean(sample(z$age, 50, replace = F ), na.rm=T)),
    mean_num = replicate(199, mean(sample(z$zombies_killed, 50, replace = F ), na.rm=T)),
    mean_edu = replicate(199, mean(sample(z$years_of_education, 50, replace = F ), na.rm=T))
  ))

s_z_mean <- s_z %>% select(starts_with("mean"))

s_200 <- rbind(s_z_mean, s_199)

sampling_summary_z <- s_200 %>% 
  summarise(
    m_height = mean(mean_height),
    sd_height = sd(mean_height),
    m_weight = mean(mean_weight),
    sd_weight = sd(mean_weight),
    m_age = mean(mean_age),
    sd_age = sd(mean_age),
    m_num = mean(mean_num),
    sd_num = sd(mean_num),
    m_edu = mean(mean_edu),
    sd_edu = sd(mean_edu),
  )

sampling_sd <- sampling_summary_z %>% select(starts_with("sd"))
s_z_se <- s_z %>% select(starts_with("se"))

print(sampling_sd)
print(s_z_se)
```

The standard deviations of the sampling distribution for each variable are similar to the standard errors estimated from the first sample of size 50

step 8

```{r}
hist(s_200$mean_height)
hist(s_200$mean_weight)
hist(s_200$mean_age)
hist(s_200$mean_num)
hist(s_200$mean_edu)
```

They are normally distributed, including those variables that were not originally drawn from a normal distribution.

step 9

```{r}
ci_95 <- s_200 %>% 
  summarise(
    ci_height = quantile(mean_height, probs = c(0.025,0.975)),
    ci_weight = quantile(mean_weight, probs =c(0.025,0.975)),
    ci_age = quantile(mean_age,probs = c(0.025,0.975)),
    ci_num = quantile(mean_num, probs =c(0.025,0.975)),
    ci_edu = quantile(mean_edu,probs = c(0.025,0.975))
  )

s_z_ci <- s_z %>% select(starts_with("ci"))

print(ci_95)
print(s_z_ci)
```

The CI based on one sample is wider than the CI based on a sampling distribution across 200 samples.

step 10

```{r}
boot_ci_mosaic <- function(data, variable) {
  boot_samples <- do(1000) * mean(sample(data[[variable]], length(data[[variable]]), replace = T))
  return(quantile(boot_samples$mean, c(0.025, 0.975)))
}

boot_ci_results <- data.frame(
  Variable = c("height", "weight", "age", "zombies_killed", "years_of_education"),
  CI_Lower = c(boot_ci_mosaic(z, "height")[1],
                boot_ci_mosaic(z, "weight")[1],
                boot_ci_mosaic(z, "age")[1],
                boot_ci_mosaic(z, "zombies_killed")[1],
                boot_ci_mosaic(z, "years_of_education")[1]),
  CI_Upper = c(boot_ci_mosaic(z, "height")[2],
                boot_ci_mosaic(z, "weight")[2],
                boot_ci_mosaic(z, "age")[2],
                boot_ci_mosaic(z, "zombies_killed")[2],
                boot_ci_mosaic(z, "years_of_education")[2])
)

print(boot_ci_results)
```

The CI generated from bootstrapping is narrower than the CIs generated in step 9.
